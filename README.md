# Learning-Hugging-Face-models

A hands-on collection of experiments and code samples for working with **Hugging Face models** â€” built by **Krish Kumar**.

---

## ğŸ“˜ About

This repository is dedicated to understanding and experimenting with models from the [Hugging Face](https://huggingface.co/) ecosystem.  
It covers key aspects such as:

- Loading and running **pre-trained transformer models**
- Fine-tuning models on **custom datasets**
- Exploring **tokenizers**, **pipelines**, and **inference**
- Logging results and managing **experiment outputs**

The goal is to build practical intuition for how large language models (LLMs) function and how they can be applied to NLP tasks.

---

## ğŸ› ï¸ Repository Structure

| File / Folder | Description |
|----------------|--------------|
| `main.py` | Example script demonstrating model loading, inference, and evaluation |
| `hf_eval_results/` | Folder for storing evaluation metrics, logs, or outputs |
| `requirements.txt` | Dependencies required to run the project |
| `LICENSE` | Project license (Apache 2.0) |

---

## â–¶ï¸ Getting Started

### 1. Clone this repository
```bash
git clone https://github.com/krisjscott/Learning-Hugging-Face-models.git
cd Learning-Hugging-Face-models
````

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

> If you donâ€™t have a `requirements.txt` yet, you can create one with:
>
> ```
> transformers
> torch
> datasets
> ```

### 3. Run the example

```bash
python main.py
```

### 4. View results

Check the `hf_eval_results/` folder for evaluation logs, predictions, and metrics.

---

## ğŸ’¡ Key Learning Goals

* Understand transformer architectures and pre-training concepts
* Experiment with Hugging Faceâ€™s `pipeline` API
* Perform inference, evaluation, and fine-tuning on different NLP tasks
* Explore optimization and deployment workflows for model use

---

## ğŸš€ Future Improvements

* Add a `notebooks/` directory with Jupyter notebooks for exploration
* Implement custom datasets and fine-tuning examples
* Integrate with FastAPI or Gradio for live inference demos
* Add hardware benchmarking (CPU vs GPU) results
* Document experiment configurations and results

---

## ğŸ“„ License

This project is licensed under the [Apache License 2.0](LICENSE).

---

## ğŸ‘¤ Author

**Krish Kumar**
ğŸ“ [GitHub Profile](https://github.com/krisjscott)

If you found this repository helpful or built something cool from it, feel free to share your work or contribute!

---


